{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3350e2e-dba6-4ae0-ac7a-272c761eca34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec9f5-d65c-49fc-84fa-b19578efded6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path('../MIMIC/physionet.org/content/mimic-cxr-jpg/get-zip/2.1.0/mimic-cxr-jpg-chest-radiographs-with-structured-labels-2.1.0')\n",
    "all_path = Path('cxr_filtered_all.csv.gz')\n",
    "structured_path = Path('all_structured_data.csv')\n",
    "unstructured_path = Path('all_unstructured_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b826b-2187-483c-be3b-cb93bd449985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files_in_directory(directory, level=0, max_depth=2):\n",
    "    if level >= max_depth:\n",
    "        return\n",
    "    \n",
    "    for item in sorted(directory.iterdir()):\n",
    "        indent = '    ' * level\n",
    "        if item.is_dir():\n",
    "            if level == max_depth - 1:\n",
    "                count = sum(1 for _ in item.iterdir())\n",
    "                print(f\"{indent}[DIR] {item.name}: {count} items\")\n",
    "            else:\n",
    "                print(f\"{indent}[DIR] {item.name}\")\n",
    "                list_files_in_directory(item, level + 1, max_depth)\n",
    "        else:\n",
    "            print(f\"{indent}{item.name}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    list_files_in_directory(data_path, max_depth=2)\n",
    "else:\n",
    "    print(f\"Directory '{data_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cf58c-25da-432e-93ce-bf528f04e3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all CSV and CSV.GZ files in the directory\n",
    "# metadata_path = Path('../MIMIC/physionet.org/content/mimic-cxr-jpg/get-zip/2.1.0/mimic-cxr-jpg-chest-radiographs-with-structured-labels-2.1.0/mimic-cxr-2.0.0-metadata.csv.gz')\n",
    "\n",
    "df = pd.read_csv(all_path, compression=\"gzip\" if all_path.suffix == \".gz\" else None)\n",
    "    \n",
    "# Print DataFrame basic information\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Print data types and non-null values count\n",
    "print(\"\\nData Types and Non-Null Value Count:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Print descriptive statistics for numeric columns\n",
    "print(\"\\nNumeric Column Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print unique value counts for each column\n",
    "print(\"\\nUnique Value Count per Column:\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd98cac-6d72-4d2a-8108-d9a2abebf81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7388bf9-f5d5-4c75-9fa7-d8fa51caae6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"StudyDateStr\"] = df[\"StudyDate\"].astype(str)\n",
    "def format_time(t):\n",
    "    try:\n",
    "        t = float(t)\n",
    "        int_part = int(t)\n",
    "        decimal_part = f\"{t:.6f}\".split(\".\")[1] \n",
    "        int_str = str(int_part).zfill(6)         \n",
    "        return f\"{int_str}.{decimal_part}\"\n",
    "    except:\n",
    "        return \"000000.000000\"\n",
    "df[\"StudyDateStr\"] = df[\"StudyDate\"].astype(str).str.zfill(8)\n",
    "df[\"StudyTimeStr\"] = df[\"StudyTime\"].apply(format_time)\n",
    "\n",
    "df[\"StudyDateTime\"] = pd.to_datetime(\n",
    "    df[\"StudyDateStr\"] + \" \" + df[\"StudyTimeStr\"],\n",
    "    format=\"%Y%m%d %H%M%S.%f\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "print(df[[\"StudyDate\", \"StudyTime\", \"StudyDateTime\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f17a59-ca54-4281-a7c3-776a58991f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df[\"StudyDate\"] = pd.to_datetime(df[\"StudyDate\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "df_sorted = df.sort_values(by=[\"subject_id\", \"StudyDateTime\",\"ViewPosition\"])\n",
    "df_sorted[\"order\"] = df_sorted.groupby(\"subject_id\").cumcount() + 1\n",
    "# df_sorted = df_sorted[df_sorted[\"ViewPosition\"] == \"AP\"]\n",
    "df_final = df_sorted[[\"subject_id\", \"study_id\", \"StudyDateTime\" ,\"dicom_id\", \"ViewPosition\" ,\"order\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4968c-360b-4269-87f6-9996a2e73507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf47d6-cd14-4178-b47d-9a81e3dea470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_key_dicom_ids(df):\n",
    "    if \"StudyDateTime\" not in df.columns:\n",
    "        raise ValueError(\"❗️Missing 'StudyDateTime' column. Please construct it first.\")\n",
    "\n",
    "    df = df[df[\"StudyDateTime\"].notna()].copy() \n",
    "    results = []\n",
    "\n",
    "    for subject_id, group in df.groupby(\"subject_id\"):\n",
    "        group = group.sort_values(\"StudyDateTime\").reset_index(drop=True)\n",
    "\n",
    "        if len(group) == 1:\n",
    "            indices = [0, 0, 0]\n",
    "        elif len(group) == 2:\n",
    "            indices = [0, 1, 1]\n",
    "        else:\n",
    "            indices = [0, len(group) // 2, len(group) - 1]\n",
    "\n",
    "        selected_dicom_ids = group.iloc[indices][\"dicom_id\"].tolist()\n",
    "        study_datetime = group.iloc[indices[1]][\"StudyDateTime\"]  \n",
    "\n",
    "        results.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"StudyDateTime\": study_datetime,\n",
    "            \"files\": selected_dicom_ids\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_actual_files = select_key_dicom_ids(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1b38c-f871-40a0-b75b-03be657734cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actual_files.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0617170-42fa-46ec-9e2c-bf11bb3b34d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(unstructured_path)\n",
    "df_labels = df_labels[['subject_id', 'icu_readmission_30d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19623412-3b80-4941-b39c-fe6ec04fe427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811769ba-1c68-4f7e-afd5-0e7a39b20cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_actual_files,\n",
    "    df_labels,\n",
    "    on='subject_id',\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "df_unmatched = df_merged[df_merged['_merge'] == 'left_only']\n",
    "\n",
    "print(f\"Unmatched (left_only) subject_id count: {len(df_unmatched)}\")\n",
    "\n",
    "print(df_unmatched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d51e7-a6a7-4a1c-9a12-3e29d81f731e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actual_files = df_merged[df_merged['_merge'] != 'left_only'].drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b67637-18c6-4f47-a72a-f481472ff3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_actual_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c518cc4-e400-4dcb-90b6-2be82aefa145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actual_files.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d1cd8-ec3d-4573-9649-64c29b841416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_images(df_actual_files, base_path, df_original, max_display=10):\n",
    "    processed_images = []\n",
    "    dicom_to_date = df_original.set_index(\"dicom_id\")[\"StudyDateTime\"].astype(str).to_dict()\n",
    "\n",
    "    shown_count = 0  \n",
    "    for _, row in tqdm(df_actual_files.iterrows(), total=len(df_actual_files), desc=\"Processing Images\"):\n",
    "        subject_id = row[\"subject_id\"]\n",
    "        dicom_list = row[\"files\"]\n",
    "\n",
    "        fig, axes = None, None\n",
    "        if shown_count < max_display:\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        for i, dicom_id in enumerate(dicom_list):\n",
    "            file_name = f\"{dicom_id}.jpg\"\n",
    "            study_date = dicom_to_date.get(dicom_id, \"Unknown\")\n",
    "\n",
    "            subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
    "            subject_dir = f\"p{subject_id}\"\n",
    "            found = False\n",
    "\n",
    "            for study_path in (base_path / subject_prefix / subject_dir).glob(\"s*\"):\n",
    "                file_path = study_path / file_name\n",
    "                if file_path.exists():\n",
    "                    img = cv2.imread(str(file_path))\n",
    "                    if img is not None:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        img = cv2.resize(img, (224, 224))\n",
    "                        img = img.astype(np.float32) / 255.0\n",
    "                        processed_images.append(img)\n",
    "\n",
    "                        if shown_count < max_display:\n",
    "                            axes[i].imshow(img)\n",
    "                            axes[i].set_title(file_name)\n",
    "                            axes[i].text(0.5, -0.1, f\"StudyDateTime: {study_date}\",\n",
    "                                         transform=axes[i].transAxes,\n",
    "                                         ha='center', va='top', fontsize=10)\n",
    "                            axes[i].axis(\"off\")\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "            if not found and shown_count < max_display:\n",
    "                axes[i].set_title(\"Not Found\")\n",
    "                axes[i].text(0.5, -0.1, f\"StudyDateTime: {study_date}\",\n",
    "                             transform=axes[i].transAxes,\n",
    "                             ha='center', va='top', fontsize=10)\n",
    "                axes[i].axis(\"off\")\n",
    "\n",
    "        if shown_count < max_display:\n",
    "            plt.suptitle(f\"Subject ID: {subject_id}\")\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()\n",
    "            shown_count += 1  \n",
    "\n",
    "    return processed_images\n",
    "\n",
    "processed_images = preprocess_images(df_actual_files, data_path / \"files\",  df_final, max_display=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01592bba-c8bc-4b2a-a6d3-02e0edc845bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(processed_images))\n",
    "print(processed_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac350f05-5b9c-49ff-a4d4-6fda9b914b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_processed_images_to_hdf5(processed_images, df_actual_files, df_original, hdf5_path=\"processed_images.h5\"):\n",
    "    dicom_to_date = df_original.set_index(\"dicom_id\")[\"StudyDateTime\"].astype(str).to_dict()\n",
    "    grouped = df_actual_files.groupby(\"subject_id\")[\"files\"].apply(list).to_dict()\n",
    "    label_dict = df_actual_files.set_index(\"subject_id\")[\"icu_readmission_30d\"].to_dict()\n",
    "\n",
    "    feature_index = 0\n",
    "    with h5py.File(hdf5_path, \"w\") as hf:\n",
    "        for subject_id, dicom_ids in grouped.items():\n",
    "            subject_imgs = []\n",
    "            subject_dates = []\n",
    "\n",
    "            for dicom_list in dicom_ids:\n",
    "                for dicom_id in dicom_list:\n",
    "                    if feature_index < len(processed_images):\n",
    "                        subject_imgs.append(processed_images[feature_index])\n",
    "                        feature_index += 1\n",
    "                    else:\n",
    "                        subject_imgs.append(np.zeros((224, 224, 3)))\n",
    "                    study_date = dicom_to_date.get(dicom_id, \"Unknown\")\n",
    "                    subject_dates.append(study_date)\n",
    "\n",
    "            while len(subject_imgs) < 3:\n",
    "                subject_imgs.append(subject_imgs[-1] if subject_imgs else np.zeros((224, 224, 3)))\n",
    "                subject_dates.append(subject_dates[-1] if subject_dates else \"Unknown\")\n",
    "\n",
    "            subject_imgs = np.array(subject_imgs[:3])\n",
    "            subject_dates = subject_dates[:3]\n",
    "\n",
    "            grp = hf.create_group(str(subject_id))\n",
    "            grp.create_dataset(\"images\", data=subject_imgs, compression=\"gzip\")\n",
    "            for i, date in enumerate(subject_dates):\n",
    "                grp.create_dataset(f\"studydate_{i}\", data=date.encode(\"utf-8\"))\n",
    "\n",
    "            if subject_id in label_dict:\n",
    "                grp.create_dataset(\"icu_readmission_30d\", data=int(label_dict[subject_id]))\n",
    "\n",
    "    print(f\"✅ Saved to {hdf5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88419b68-85e4-4fdc-a7ad-dc632315cf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_processed_images_to_hdf5(processed_images, df_actual_files, df_final, hdf5_path=\"processed_images_readmission.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8793e-8b7a-45db-9641-fbd49a9a2c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
