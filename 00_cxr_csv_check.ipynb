{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e79a4-a49b-4948-b9ba-04d643ff0bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508d9d6-769e-4a73-94da-f73517019d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path('../MIMIC/physionet.org/content/mimic-cxr-jpg/get-zip/2.1.0/mimic-cxr-jpg-chest-radiographs-with-structured-labels-2.1.0')\n",
    "icu_data_path = Path('../MIMIC/MIMICIV/physionet.org/files/mimiciv/3.1/icu')\n",
    "icustay_path = icu_data_path / 'icustays.csv.gz'\n",
    "hosp_data_path = Path('../MIMIC/MIMICIV/physionet.org/files/mimiciv/3.1/hosp')\n",
    "note_path = Path('../MIMIC/MIMICIV/physionet.org/files/mimic-iv-note/2.2/note')\n",
    "discharge_data_path = note_path / 'discharge.csv.gz'\n",
    "radiology_data_path = note_path / 'radiology.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fc2ad-7760-4f14-aab0-5aea990a9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory(directory, level=0, max_depth=2):\n",
    "    if level >= max_depth:\n",
    "        return\n",
    "    \n",
    "    for item in sorted(directory.iterdir()):\n",
    "        indent = '    ' * level\n",
    "        if item.is_dir():\n",
    "            if level == max_depth - 1:\n",
    "                count = sum(1 for _ in item.iterdir())\n",
    "                print(f\"{indent}[DIR] {item.name}: {count} items\")\n",
    "            else:\n",
    "                print(f\"{indent}[DIR] {item.name}\")\n",
    "                list_files_in_directory(item, level + 1, max_depth)\n",
    "        else:\n",
    "            print(f\"{indent}{item.name}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    list_files_in_directory(data_path, max_depth=2)\n",
    "else:\n",
    "    print(f\"Directory '{data_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a30be-2b0c-4fc5-b35e-abb8c05cec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CSV and CSV.GZ files in the directory\n",
    "metadata_path = Path('../MIMIC/physionet.org/content/mimic-cxr-jpg/get-zip/2.1.0/mimic-cxr-jpg-chest-radiographs-with-structured-labels-2.1.0/mimic-cxr-2.0.0-metadata.csv.gz')\n",
    "\n",
    "df = pd.read_csv(metadata_path, compression=\"gzip\" if metadata_path.suffix == \".gz\" else None)\n",
    "    \n",
    "# Print DataFrame basic information\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Print data types and non-null values count\n",
    "print(\"\\nData Types and Non-Null Value Count:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Print descriptive statistics for numeric columns\n",
    "print(\"\\nNumeric Column Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print unique value counts for each column\n",
    "print(\"\\nUnique Value Count per Column:\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aabc49-f051-4f2b-b53a-d9e40fbc2c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all CSV and CSV.GZ files in the directory\n",
    "df_icustay = pd.read_csv(icustay_path, compression=\"gzip\" if metadata_path.suffix == \".gz\" else None)\n",
    "    \n",
    "# Print DataFrame basic information\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Print data types and non-null values count\n",
    "print(\"\\nData Types and Non-Null Value Count:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Print descriptive statistics for numeric columns\n",
    "print(\"\\nNumeric Column Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Print unique value counts for each column\n",
    "print(\"\\nUnique Value Count per Column:\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57209a37-3af9-4a28-9853-ec2180a56e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"StudyDateStr\"] = df[\"StudyDate\"].astype(str)\n",
    "def format_time(t):\n",
    "    try:\n",
    "        t = float(t)\n",
    "        int_part = int(t)\n",
    "        decimal_part = f\"{t:.6f}\".split(\".\")[1]  \n",
    "        int_str = str(int_part).zfill(6)       \n",
    "        return f\"{int_str}.{decimal_part}\"\n",
    "    except:\n",
    "        return \"000000.000000\"\n",
    "df[\"StudyDateStr\"] = df[\"StudyDate\"].astype(str).str.zfill(8)\n",
    "df[\"StudyTimeStr\"] = df[\"StudyTime\"].apply(format_time)\n",
    "\n",
    "df[\"StudyDateTime\"] = pd.to_datetime(\n",
    "    df[\"StudyDateStr\"] + \" \" + df[\"StudyTimeStr\"],\n",
    "    format=\"%Y%m%d %H%M%S.%f\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "print(df[[\"StudyDate\", \"StudyTime\", \"StudyDateTime\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544972a-c519-4dca-b726-20f50d8f365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_nat_rows(df, datetime_col=\"StudyDateTime\", preview=5):\n",
    "    if datetime_col not in df.columns:\n",
    "        raise ValueError(f\"❌ '{datetime_col}' is not in DataFrame.\")\n",
    "\n",
    "    nat_rows = df[df[datetime_col].isna()]\n",
    "    count = len(nat_rows)\n",
    "    print(f\"⚠️ '{datetime_col}' Nat counts: {count}\")\n",
    "\n",
    "    if count > 0:\n",
    "        print(f\"\\n📋 First {preview} as：\")\n",
    "        display(nat_rows.head(preview))\n",
    "    \n",
    "    return nat_rows\n",
    "bad_rows = report_nat_rows(df, datetime_col=\"StudyDateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4ddc7-ab0f-448a-8141-aa4ed06db32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"StudyDate\"] = pd.to_datetime(df[\"StudyDate\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "df_sorted = df.sort_values(by=[\"subject_id\", \"StudyDateTime\",\"ViewPosition\"])\n",
    "df_sorted[\"order\"] = df_sorted.groupby(\"subject_id\").cumcount() + 1\n",
    "# df_sorted = df_sorted[df_sorted[\"ViewPosition\"] == \"AP\"]\n",
    "df_final = df_sorted[[\"subject_id\", \"study_id\", \"StudyDateTime\" ,\"dicom_id\", \"ViewPosition\" ,\"order\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979e805-326d-4ec3-b639-56009df4daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb8266-f6fe-43c0-8a30-1a341f2ef0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def report_time_spans(df_sorted, threshold_hours=24):\n",
    "    df_sorted = df_sorted.copy()\n",
    "\n",
    "    if \"StudyDateTime\" not in df_sorted.columns:\n",
    "        raise ValueError(\"❗️Missing 'StudyDateTime' column. Please create it before running this function.\")\n",
    "\n",
    "    df_sorted = df_sorted[df_sorted[\"StudyDateTime\"].notna()] \n",
    "    span_info = []\n",
    "\n",
    "    for subject_id, group in df_sorted.groupby(\"subject_id\"):\n",
    "        group = group.sort_values(\"StudyDateTime\").reset_index(drop=True)\n",
    "        t0 = group[\"StudyDateTime\"].iloc[0]\n",
    "        t1 = group[\"StudyDateTime\"].iloc[-1]\n",
    "        span_hours = (t1 - t0).total_seconds() / 3600 if len(group) > 1 else 0.0\n",
    "\n",
    "        span_info.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"start_time\": t0,\n",
    "            \"end_time\": t1,\n",
    "            \"span_hours\": span_hours\n",
    "        })\n",
    "\n",
    "    span_df = pd.DataFrame(span_info)\n",
    "    total = len(span_df)\n",
    "    below_thresh = (span_df[\"span_hours\"] < threshold_hours).sum()\n",
    "    print(f\"✅ {total} subject_ids in total; among them, {below_thresh} have a time span shorter than {threshold_hours} hours ({below_thresh/total:.1%}).\")\n",
    "\n",
    "    return span_df\n",
    "\n",
    "def filter_by_time_window(df, first_24=False, last_24=False, last_48=False, return_df=False):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if \"StudyDateTime\" not in df.columns:\n",
    "        raise ValueError(\"❌ No 'StudyDateTime'\")\n",
    "\n",
    "    df = df[df[\"StudyDateTime\"].notna()] \n",
    "    result_frames = []\n",
    "\n",
    "    for subject_id, group in df.groupby(\"subject_id\"):\n",
    "        group = group.sort_values(\"StudyDateTime\").reset_index(drop=True)\n",
    "\n",
    "        if len(group) == 1:\n",
    "            result_frames.append(group)\n",
    "            continue\n",
    "\n",
    "        t0 = group[\"StudyDateTime\"].iloc[0]\n",
    "        t_end = group[\"StudyDateTime\"].iloc[-1]\n",
    "\n",
    "        group[\"relative_hours_from_start\"] = (group[\"StudyDateTime\"] - t0).dt.total_seconds() / 3600\n",
    "        group[\"relative_hours_to_end\"] = (t_end - group[\"StudyDateTime\"]).dt.total_seconds() / 3600\n",
    "\n",
    "        selected_rows = pd.DataFrame()\n",
    "\n",
    "        if first_24:\n",
    "            selected_rows = pd.concat([selected_rows, group[group[\"relative_hours_from_start\"] <= 24]])\n",
    "\n",
    "        if last_24:\n",
    "            selected_rows = pd.concat([selected_rows, group[group[\"relative_hours_to_end\"] <= 24]])\n",
    "\n",
    "        if last_48:\n",
    "            selected_rows = pd.concat([selected_rows, group[group[\"relative_hours_to_end\"] <= 48]])\n",
    "\n",
    "        if not selected_rows.empty:\n",
    "            result_frames.append(selected_rows)\n",
    "\n",
    "    if result_frames:\n",
    "        combined = pd.concat(result_frames).drop_duplicates()\n",
    "        total = combined[\"dicom_id\"].nunique()\n",
    "        print(f\"✅ Total selected dicom_id: {total}\")\n",
    "        if return_df:\n",
    "            return combined\n",
    "    else:\n",
    "        print(\"⚠️ No time window selected or no StudyDateTime available.\")\n",
    "        if return_df:\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3604612-c479-4e5b-bf45-0792f147eb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "span_df = report_time_spans(df_final, threshold_hours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f534ada-11c3-4386-9876-35c45c860039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = df_final.merge(df_icustay[[\"subject_id\", \"stay_id\", \"intime\" ,\"outtime\",\"los\"]], on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b610b2-d105-49e9-95cb-b233aac0bf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_merged[df_merged['subject_id'].isin([10000032, 10001217])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3537b8-6d74-4e60-9f7d-c649b187530f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_merged[df_merged['stay_id'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b8514-576d-4c20-9bc3-ae7dbff55367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged['StudyDateTime'] = pd.to_datetime(df_merged['StudyDateTime'])\n",
    "df_merged['intime'] = pd.to_datetime(df_merged['intime'])\n",
    "df_merged['outtime'] = pd.to_datetime(df_merged['outtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15642d-3b24-4e9e-bf43-8c024bfe7b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_icu_count = df_merged['stay_id'].isna().sum()\n",
    "icu_counts = df_merged.dropna(subset=['stay_id']).groupby('subject_id')['stay_id'].nunique()\n",
    "more_than_once_icu = (icu_counts > 1).sum()\n",
    "df_has_icu = df_merged[df_merged['stay_id'].notna()]\n",
    "before_icu = df_has_icu[df_has_icu['StudyDateTime'] < df_has_icu['intime']].shape[0]\n",
    "within_icu = df_has_icu[(df_has_icu['StudyDateTime'] >= df_has_icu['intime']) & \n",
    "                        (df_has_icu['StudyDateTime'] <= df_has_icu['outtime'])].shape[0]\n",
    "after_icu = df_has_icu[df_has_icu['StudyDateTime'] > df_has_icu['outtime']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fd2b7-1c85-468e-9b23-b8f62d48eafe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Summary:\")\n",
    "print(f\"1. Number of images without an ICU stay: {no_icu_count}\")\n",
    "print(f\"2. Number of subject_ids with more than one ICU stay: {more_than_once_icu}\")\n",
    "print(f\"3. Distribution of StudyDateTime relative to ICU stay:\")\n",
    "print(f\"   - Before ICU stay: {before_icu}\")\n",
    "print(f\"   - During ICU stay: {within_icu}\")\n",
    "print(f\"   - After ICU stay: {after_icu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4eef3-6529-403c-92bd-3d0ce1d8cc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_icu = (\n",
    "    df_merged[df_merged['stay_id'].notna()]\n",
    "    .sort_values(['subject_id', 'intime']) \n",
    "    .drop_duplicates(subset='subject_id', keep='first') \n",
    ")\n",
    "df_first_icu = df_merged[['subject_id', 'StudyDateTime', 'dicom_id', 'ViewPosition', 'order']].drop_duplicates()\n",
    "df_first_icu = df_first_icu.merge(\n",
    "    first_icu[['subject_id', 'stay_id', 'intime', 'outtime', 'los']], \n",
    "    on='subject_id', how='left'\n",
    ")\n",
    "df_first_icu['StudyDateTime'] = pd.to_datetime(df_first_icu['StudyDateTime'])\n",
    "df_first_icu['intime'] = pd.to_datetime(df_first_icu['intime'])\n",
    "df_first_icu['outtime'] = pd.to_datetime(df_first_icu['outtime'])\n",
    "\n",
    "no_icu_count = df_first_icu['stay_id'].isna().sum()\n",
    "\n",
    "before_icu = df_first_icu[df_first_icu['StudyDateTime'] < df_first_icu['intime']].shape[0]\n",
    "within_icu = df_first_icu[(df_first_icu['StudyDateTime'] >= df_first_icu['intime']) &\n",
    "                          (df_first_icu['StudyDateTime'] <= df_first_icu['outtime'])].shape[0]\n",
    "after_icu = df_first_icu[df_first_icu['StudyDateTime'] > df_first_icu['outtime']].shape[0]\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(f\"1. Number of images without an ICU stay: {no_icu_count}\")\n",
    "print(f\"2. Distribution of StudyDateTime relative to the first ICU stay:\")\n",
    "print(f\"   - Before first ICU stay: {before_icu}\")\n",
    "print(f\"   - During first ICU stay: {within_icu}\")\n",
    "print(f\"   - After first ICU stay: {after_icu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a2968-0cbd-4848-b7b9-f797d08e0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_icu_ids = df_first_icu[df_first_icu['StudyDateTime'] < df_first_icu['intime']]['subject_id'].unique()\n",
    "within_icu_ids = df_first_icu[\n",
    "    (df_first_icu['StudyDateTime'] >= df_first_icu['intime']) &\n",
    "    (df_first_icu['StudyDateTime'] <= df_first_icu['outtime'])\n",
    "]['subject_id'].unique()\n",
    "after_icu_ids = df_first_icu[df_first_icu['StudyDateTime'] > df_first_icu['outtime']]['subject_id'].unique()\n",
    "total_unique_subjects = df_first_icu['subject_id'].nunique()\n",
    "no_icu_ids = df_first_icu[df_first_icu['stay_id'].isna()]['subject_id'].unique()\n",
    "num_no_icu = len(no_icu_ids)\n",
    "print(\"Summary:\")\n",
    "print(f\"1. Total unique subject_ids: {total_unique_subjects}\")\n",
    "print(f\"2. Number of subject_ids with more than one ICU stay: {more_than_once_icu}\")\n",
    "print(f\"3. Unique subject_id counts by StudyDateTime (relative to first ICU stay):\")\n",
    "print(f\"   - Before first ICU stay: {len(before_icu_ids)}\")\n",
    "print(f\"   - During first ICU stay: {len(within_icu_ids)}\")\n",
    "print(f\"   - After first ICU stay: {len(after_icu_ids)}\")\n",
    "print(f\"   - No ICU stay: {len(no_icu_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22783e-24e4-4dde-b6c0-f5ede30d2810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_icu_ids = df_first_icu[df_first_icu['stay_id'].notna()]['subject_id'].unique()\n",
    "\n",
    "true_no_icu_ids = set(no_icu_ids) - set(has_icu_ids)\n",
    "num_true_no_icu = len(true_no_icu_ids)\n",
    "\n",
    "print(\"Summary (exclude duplicates):\")\n",
    "print(f\"1. Total unique subject_ids: {total_unique_subjects}\")\n",
    "print(f\"2. Number of subject_ids with more than one ICU stay: {more_than_once_icu}\")\n",
    "print(f\"3. Unique subject_id counts by StudyDateTime (relative to first ICU stay):\")\n",
    "print(f\"   - Before first ICU stay: {len(before_icu_ids)}\")\n",
    "print(f\"   - During first ICU stay: {len(within_icu_ids)}\")\n",
    "print(f\"   - After first ICU stay: {len(after_icu_ids)}\")\n",
    "print(f\"   - No ICU stay (never appeared in ICU at all): {num_true_no_icu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577ce32-100a-4fba-a0df-0cc7a02d3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discharge = pd.read_csv(discharge_data_path)\n",
    "df_radiology = pd.read_csv(radiology_data_path)\n",
    "\n",
    "df_discharge = df_discharge[df_discharge['text'].notna()]\n",
    "df_radiology = df_radiology[df_radiology['text'].notna()]\n",
    "\n",
    "discharge_ids = set(df_discharge['subject_id'].unique())\n",
    "radiology_ids = set(df_radiology['subject_id'].unique())\n",
    "\n",
    "all_note_subjects = discharge_ids.union(radiology_ids)\n",
    "\n",
    "print(f\"Discharge note subject count: {len(discharge_ids)}\")\n",
    "print(f\"Radiology note subject count: {len(radiology_ids)}\")\n",
    "print(f\"Total unique subjects with notes: {len(all_note_subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08390755-92f3-4e0a-b857-8e5a14f42385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37129e97-50cf-4d3b-b1f7-d0eff9f8d690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_radiology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fab99-0d53-4d88-b7e7-b86abd9df606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_discharge['note_type'] = 'discharge'\n",
    "df_radiology['note_type'] = 'radiology'\n",
    "\n",
    "df_note = pd.concat([df_discharge, df_radiology], ignore_index=True)\n",
    "\n",
    "df_note['charttime'] = pd.to_datetime(df_note['charttime'])\n",
    "\n",
    "df_note = df_note[df_note['text'].notna()]\n",
    "\n",
    "print(df_note.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc89156-c65c-4536-b11f-627260d44d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "note_ids = set(df_note['subject_id'].unique())\n",
    "\n",
    "before_with_notes = set(before_icu_ids) & note_ids\n",
    "within_with_notes = set(within_icu_ids) & note_ids\n",
    "after_with_notes = set(after_icu_ids) & note_ids\n",
    "true_no_icu_with_notes = true_no_icu_ids & note_ids \n",
    "\n",
    "print(\"Summary:\")\n",
    "print(f\"1. Total unique subject_ids: {total_unique_subjects}\")\n",
    "# print(f\"2. Number of subject_ids with more than one ICU stay: {more_than_once_icu}\")\n",
    "print(f\"2. Before first ICU stay with notes: {len(before_with_notes)}\")\n",
    "print(f\"3. During first ICU stay with notes: {len(within_with_notes)}\")\n",
    "print(f\"4. After first ICU stay with notes: {len(after_with_notes)}\")\n",
    "print(f\"5. No ICU stay at all with notes: {len(true_no_icu_with_notes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e97ea-19fe-4163-943e-f4af2f6234c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects_with_notes = set(df_note['subject_id'].unique())\n",
    "\n",
    "df_first_icu['StudyDateTime'] = pd.to_datetime(df_first_icu['StudyDateTime'])\n",
    "df_first_icu['intime'] = pd.to_datetime(df_first_icu['intime'])\n",
    "\n",
    "images_within_24h = df_first_icu[\n",
    "    df_first_icu['StudyDateTime'] <= df_first_icu['intime'] + pd.Timedelta(hours=24)\n",
    "]\n",
    "\n",
    "images_within_48h = df_first_icu[\n",
    "    df_first_icu['StudyDateTime'] <= df_first_icu['intime'] + pd.Timedelta(hours=48)\n",
    "]\n",
    "\n",
    "subjects_with_images_24h = set(images_within_24h['subject_id'].unique())\n",
    "subjects_with_images_48h = set(images_within_48h['subject_id'].unique())\n",
    "\n",
    "cohort_subjects_24h = subjects_with_images_24h & subjects_with_notes\n",
    "cohort_subjects_48h = subjects_with_images_48h & subjects_with_notes\n",
    "\n",
    "print(\"In-ICU mortality cohort (based on image before/within first ICU stay + clinical notes):\")\n",
    "print(f\"1. Subjects with CXR before or within 24h and clinical note: {len(cohort_subjects_24h)}\")\n",
    "print(f\"2. Subjects with CXR before or within 48h and clinical note: {len(cohort_subjects_48h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660e0fb-2cbd-41bd-8c27-09d227608f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_within_visit = df_first_icu[\n",
    "    df_first_icu['StudyDateTime'] <= df_first_icu['outtime']\n",
    "]\n",
    "subjects_with_images = set(images_within_visit['subject_id'].unique())\n",
    "cohort_subjects_all = subjects_with_images & subjects_with_notes\n",
    "print(f\"3. Subjects with CXR before or during and clinical note: {len(cohort_subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b81875-ec9c-4e3c-b525-6f76f7f4fa4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_first_icu['StudyDateTime'] = pd.to_datetime(df_first_icu['StudyDateTime'])\n",
    "df_first_icu['outtime'] = pd.to_datetime(df_first_icu['outtime'])\n",
    "\n",
    "images_within_last_48h = df_first_icu[\n",
    "    (df_first_icu['StudyDateTime'] <= df_first_icu['outtime']) &\n",
    "    (df_first_icu['StudyDateTime'] >= df_first_icu['outtime'] - pd.Timedelta(hours=48))\n",
    "]\n",
    "\n",
    "subjects_with_images_last_48h = set(images_within_last_48h['subject_id'].unique())\n",
    "\n",
    "cohort_subjects_last_48h = subjects_with_images_last_48h & subjects_with_notes\n",
    "\n",
    "print(\"Readmission cohort (based on image within last 48h of first ICU stay + clinical notes):\")\n",
    "print(f\"Subjects with CXR in last 48h before ICU discharge and clinical note: {len(cohort_subjects_last_48h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea9ff5-e272-4607-8b8d-cbd49b11328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cxr_metadata_by_subjects(\n",
    "    metadata_path: str,\n",
    "    cohort_24h: set,\n",
    "    cohort_48h: set,\n",
    "    cohort_l48h: set,\n",
    "    cohort_all: set,\n",
    "    output_24h_path: str = \"cxr_f24h_metadata.csv.gz\",\n",
    "    output_48h_path: str = \"cxr_f48h_metadata.csv.gz\",\n",
    "    output_l48h_path: str = \"cxr_l48h_metadata.csv.gz\",\n",
    "    output_all_path: str = \"cxr_all_metadata.csv.gz\"\n",
    "):\n",
    "\n",
    "    df_metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "    df_24h = df_metadata[df_metadata['subject_id'].isin(cohort_24h)]\n",
    "    df_48h = df_metadata[df_metadata['subject_id'].isin(cohort_48h)]\n",
    "    df_l48h = df_metadata[df_metadata['subject_id'].isin(cohort_l48h)]\n",
    "    df_all = df_metadata[df_metadata['subject_id'].isin(cohort_all)]\n",
    "\n",
    "    df_24h.to_csv(output_24h_path, index=False, compression='gzip')\n",
    "    df_48h.to_csv(output_48h_path, index=False, compression='gzip')\n",
    "    df_l48h.to_csv(output_l48h_path, index=False, compression='gzip')\n",
    "    df_all.to_csv(output_all_path, index=False, compression='gzip')\n",
    "\n",
    "    print(f\"✅ Saved {len(df_24h)} rows to {output_24h_path}\")\n",
    "    print(f\"✅ Saved {len(df_48h)} rows to {output_48h_path}\")\n",
    "    print(f\"✅ Saved {len(df_l48h)} rows to {output_l48h_path}\")\n",
    "    print(f\"✅ Saved {len(df_all)} rows to {output_all_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5650c-7d89-4d48-8b82-f9518823aa6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract_cxr_metadata_by_subjects(\n",
    "#     metadata_path=metadata_path,\n",
    "#     cohort_24h=cohort_subjects_24h,\n",
    "#     cohort_48h=cohort_subjects_48h,\n",
    "#     cohort_l48h=cohort_subjects_last_48h,\n",
    "#     cohort_all=cohort_subjects_all,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3a9c5-a93e-47f6-b031-1ebfb2381b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cxr_metadata_by_time(\n",
    "    metadata_path: str,\n",
    "    df_first_icu: pd.DataFrame,\n",
    "    output_24h_path: str = \"cxr_f24h_metadata.csv.gz\",\n",
    "    output_48h_path: str = \"cxr_f48h_metadata.csv.gz\",\n",
    "    output_l48h_path: str = \"cxr_l48h_metadata.csv.gz\",\n",
    "    output_all_path: str = \"cxr_all_metadata.csv.gz\"\n",
    "):\n",
    "    df_metadata = pd.read_csv(metadata_path)\n",
    "    original_columns = df_metadata.columns.tolist() \n",
    "\n",
    "    if 'StudyDateTime' not in df_metadata.columns:\n",
    "        if 'StudyDate' in df_metadata.columns and 'StudyTime' in df_metadata.columns:\n",
    "            df_metadata['StudyDateStr'] = df_metadata['StudyDate'].astype(str).str.zfill(8)\n",
    "\n",
    "            def format_time(t):\n",
    "                try:\n",
    "                    t = float(t)\n",
    "                    int_part = int(t)\n",
    "                    decimal_part = f\"{t:.6f}\".split(\".\")[1]\n",
    "                    int_str = str(int_part).zfill(6)\n",
    "                    return f\"{int_str}.{decimal_part}\"\n",
    "                except:\n",
    "                    return \"000000.000000\"\n",
    "\n",
    "            df_metadata['StudyTimeStr'] = df_metadata['StudyTime'].apply(format_time)\n",
    "            df_metadata['StudyDateTime'] = pd.to_datetime(\n",
    "                df_metadata['StudyDateStr'] + \" \" + df_metadata['StudyTimeStr'],\n",
    "                format=\"%Y%m%d %H%M%S.%f\",\n",
    "                errors='coerce'\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Metadata missing both 'StudyDateTime' and ('StudyDate', 'StudyTime') to generate StudyDateTime.\")\n",
    "\n",
    "    df_first_icu['intime'] = pd.to_datetime(df_first_icu['intime'])\n",
    "    df_first_icu['outtime'] = pd.to_datetime(df_first_icu['outtime'])\n",
    "\n",
    "    df = df_metadata.merge(df_first_icu[['subject_id', 'intime', 'outtime']], on='subject_id', how='left')\n",
    "\n",
    "    df_24h = df[\n",
    "        df['StudyDateTime'] <= df['intime'] + pd.Timedelta(hours=24)\n",
    "    ]\n",
    "    df_48h = df[\n",
    "        df['StudyDateTime'] <= df['intime'] + pd.Timedelta(hours=48)\n",
    "    ]\n",
    "    df_l48h = df[\n",
    "        (df['StudyDateTime'] <= df['outtime']) &\n",
    "        (df['StudyDateTime'] >= df['outtime'] - pd.Timedelta(hours=48))\n",
    "    ]\n",
    "    df_all = df[\n",
    "        (df['StudyDateTime'] <= df['outtime']) \n",
    "    ]\n",
    "\n",
    "    df_24h[original_columns].to_csv(output_24h_path, index=False, compression='gzip')\n",
    "    df_48h[original_columns].to_csv(output_48h_path, index=False, compression='gzip')\n",
    "    df_l48h[original_columns].to_csv(output_l48h_path, index=False, compression='gzip')\n",
    "    df_all[original_columns].to_csv(output_all_path, index=False, compression='gzip')\n",
    "\n",
    "    print(f\"✅ Saved {len(df_24h)} rows to {output_24h_path}\")\n",
    "    print(f\"✅ Saved {len(df_48h)} rows to {output_48h_path}\")\n",
    "    print(f\"✅ Saved {len(df_l48h)} rows to {output_l48h_path}\")\n",
    "    print(f\"✅ Saved {len(df_all)} rows to {output_all_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ca19d-640a-4d57-9960-e76ce567c7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_cxr_metadata_by_time(\n",
    "    metadata_path=metadata_path,\n",
    "    df_first_icu=df_first_icu,\n",
    "    output_24h_path=\"cxr_filtered_f24h.csv.gz\",\n",
    "    output_48h_path=\"cxr_filtered_f48h.csv.gz\",\n",
    "    output_l48h_path=\"cxr_filtered_l48h.csv.gz\",\n",
    "    output_all_path=\"cxr_filtered_all.csv.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220a9fa-6c1c-49a0-90a9-0ad2f4f8580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
